# ğŸ—ï¸ Construction Photo Analyzer

> Local GPU-powered photo analysis and organization tool for construction projects with on-device AI models

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.10%2B-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109.0-green)
![PyTorch](https://img.shields.io/badge/PyTorch-2.1.2-red)

## ğŸ“‹ Overview

**Construction Photo Analyzer** is an intelligent photo organization system designed for construction professionals. It automatically categorizes large databases of construction site photos into organized categories using GPU-accelerated AI models running entirely on your local machine.

### Key Features

- ğŸš€ **Local GPU Acceleration** - ResNet50 inference at ~50ms per image (single) or ~11ms per image (batch)
- ğŸ¯ **35+ Construction Categories** - Interior, Exterior, MEP Systems, Structure, Finishing & Details
- ğŸ“Š **Batch Processing** - Analyze up to 90 images/second with GPU optimization
- ğŸ”’ **Privacy-First** - All processing happens locally, no cloud uploads
- ğŸ¨ **Modern UI** - Drag-and-drop interface with real-time analysis progress
- ğŸ“ **Export Ready** - CSV export for integration with project management tools
- ğŸ³ **Docker Support** - One-command deployment with NVIDIA GPU support

## ğŸ¬ Quick Start

### Prerequisites

- NVIDIA GPU with CUDA support (Compute Capability 3.5+)
- CUDA Toolkit 11.8 or 12.1
- Python 3.10 or 3.11
- 8GB+ VRAM recommended
- Docker with NVIDIA Container Toolkit (for containerized deployment)

### Installation

```bash
# Clone the repository
git clone https://github.com/zordhalo/photo-organizer.git
cd photo-organizer

# Backend setup
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Verify GPU setup
python verify_setup.py

# Start the backend server
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

# Open the frontend (in another terminal)
cd ..
# Serve index.html with any static file server
python -m http.server 3000
```

Visit `http://localhost:3000` in your browser and ensure the backend shows "â— Connected"

### Docker Deployment (Recommended)

```bash
cd backend

# Build and run with GPU support
docker-compose up -d

# Check GPU access
docker exec photo-organizer nvidia-smi

# View logs
docker-compose logs -f
```

## ğŸ—ï¸ Architecture

### Tech Stack

**Backend:**
- FastAPI 0.109.0 - Modern async web framework
- PyTorch 2.1.2 - GPU-accelerated deep learning
- ResNet50 - Pre-trained vision model from torchvision
- Pydantic - Data validation and settings management
- Uvicorn - ASGI server with WebSocket support

**Frontend:**
- Vanilla JavaScript - No dependencies, fast loading
- WebSocket - Real-time analysis progress updates
- Modern CSS Grid - Responsive layout
- Drag & Drop API - Intuitive file uploads

**Infrastructure:**
- Docker - Containerized deployment
- NVIDIA CUDA 11.8 - GPU acceleration
- Docker Compose - Multi-container orchestration

### Project Structure

```
photo-organizer/
â”œâ”€â”€ backend/                    # FastAPI backend application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py            # FastAPI app entry point
â”‚   â”‚   â”œâ”€â”€ config.py          # Configuration & settings
â”‚   â”‚   â”œâ”€â”€ api/               # API routes
â”‚   â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ health.py  # Health check endpoints
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ analyze.py # Analysis endpoints
â”‚   â”‚   â”‚   â””â”€â”€ dependencies.py
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py     # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ vision_service.py    # GPU inference service
â”‚   â”‚   â”‚   â””â”€â”€ category_service.py  # Category mapping
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ logger.py      # Logging utilities
â”‚   â”œâ”€â”€ tests/                 # Unit & integration tests
â”‚   â”œâ”€â”€ requirements.txt       # Python dependencies
â”‚   â”œâ”€â”€ Dockerfile            # NVIDIA CUDA Docker image
â”‚   â”œâ”€â”€ docker-compose.yml    # GPU-enabled orchestration
â”‚   â”œâ”€â”€ verify_setup.py       # Environment verification
â”‚   â””â”€â”€ README.md             # Backend documentation
â”œâ”€â”€ index.html                # Frontend single-page application
â””â”€â”€ README.md                 # This file
```

## ğŸ“Š Performance Metrics

Based on testing with NVIDIA RTX 3060 (8GB VRAM):

| Metric | Value |
|--------|-------|
| Single Image Latency | ~50ms |
| Batch (10 images) per Image | ~11ms |
| Throughput (Batch) | 90+ images/second |
| GPU Memory Usage | <2GB (ResNet50) |
| Model Loading Time | ~2 seconds |
| WebSocket Latency | <10ms |

**4.5x Speedup** with batch processing vs. single image inference

## ğŸ¯ Construction Categories

The system recognizes 35+ specialized construction categories across 5 major domains:

### ğŸ  Interior (8 categories)
- Bathroom, Kitchen, Living Areas, Bedrooms
- Flooring, Drywall & Painting, Insulation, Doors & Hardware

### ğŸ—ï¸ Exterior (7 categories)
- Roofing, Siding & Cladding, Windows & Doors
- Foundation & Basement, Landscaping, Gutters, Exterior Paint

### âš¡ MEP Systems (5 categories)
- Plumbing, Electrical, HVAC, Natural Gas, Low Voltage

### ğŸ”¨ Structure (4 categories)
- Framing, Concrete Work, Excavation, Structural Steel

### âœ¨ Finishing & Details (5 categories)
- Trim & Molding, Hardware & Fixtures, Appliances, Lighting, Final Inspection

## ğŸš€ Development Roadmap

### Phase Status

| Phase | Status | Time Est. | Description |
|-------|--------|-----------|-------------|
| **Phase 1** | âœ… Complete | 2 hours | Environment Setup - CUDA, Python, Project Structure |
| **Phase 2** | âœ… Complete | 4 hours | Core Backend Architecture - FastAPI & Data Models |
| **Phase 3** | âœ… Complete | 5 hours | AI Model Integration - GPU Vision Service |
| **Phase 4** | âœ… Complete | 3 hours | API Endpoints - Image Analysis Routes |
| **Phase 5** | ğŸ”„ In Progress | 3 hours | Testing & Optimization - Performance Tuning |
| **Phase 6** | ğŸ”„ In Progress | 3 hours | Docker Deployment - GPU Containerization |
| **Phase 7** | â³ Pending | 2 hours | End-to-End Integration Testing |

**Total Development Time:** ~22 hours

### ğŸ“Œ Current Sprint: Testing & Optimization (Phase 5)

**Open Issues:**
- [Issue #7](https://github.com/zordhalo/photo-organizer/issues/7) - Testing & Optimization
- [Issue #8](https://github.com/zordhalo/photo-organizer/issues/8) - Docker Deployment
- [Issue #9](https://github.com/zordhalo/photo-organizer/issues/9) - Integration Testing

**Next Steps:**
1. Implement comprehensive unit tests (target: >80% coverage)
2. Add FP16 quantization for 2x inference speedup
3. Optimize batch size tuning and GPU memory management
4. Complete Docker configuration with multi-stage builds
5. Conduct end-to-end testing with real construction photos

### Completed Milestones

âœ… **Phase 1-4 Completed** (December 2024)
- GPU environment setup with CUDA 11.8
- FastAPI application with CORS middleware
- ResNet50 model integration with PyTorch
- Single & batch image analysis endpoints
- WebSocket support for real-time updates
- Category mapping with keyword fallback
- Frontend with drag-and-drop UI

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file in the `backend/` directory:

```env
# Application
APP_NAME=Construction Photo Analyzer
DEBUG=True
HOST=0.0.0.0
PORT=8000

# GPU Configuration
CUDA_VISIBLE_DEVICES=0
USE_GPU=true
MODEL_DEVICE=cuda
BATCH_SIZE=8

# Model Settings
MODEL_NAME=resnet50
CONFIDENCE_THRESHOLD=0.6

# CORS Settings
ALLOWED_ORIGINS=http://localhost:3000,http://localhost:5173
```

### GPU Memory Optimization

For systems with limited VRAM (<8GB):

```python
# In backend/app/services/vision_service.py

# Enable memory-efficient inference
torch.backends.cudnn.benchmark = True

# Use FP16 precision (2x faster, half memory)
model = model.half()
input_tensor = input_tensor.half()

# Adjust batch size
BATCH_SIZE = 4  # Reduce if OOM errors occur
```

## ğŸ“– API Documentation

### Endpoints

#### Health Check
```bash
GET /api/health
```

Response:
```json
{
  "status": "healthy",
  "version": "1.0.0",
  "device": "cuda",
  "gpu_available": true,
  "gpu_name": "NVIDIA GeForce RTX 3060",
  "categories_loaded": 35
}
```

#### Single Image Analysis
```bash
POST /api/v1/analyze
Content-Type: multipart/form-data

file: <image_file>
```

#### Batch Analysis
```bash
POST /api/v1/batch-analyze
Content-Type: multipart/form-data

files: <image_file_1>
files: <image_file_2>
...
```

#### Get Categories
```bash
GET /api/v1/categories
```

#### System Stats
```bash
GET /api/v1/stats
```

### WebSocket

Connect to `ws://localhost:8000/ws/analysis` for real-time analysis progress:

```javascript
const ws = new WebSocket('ws://localhost:8000/ws/analysis');

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  
  if (data.type === 'progress') {
    console.log(`Progress: ${data.current}/${data.total}`);
  }
  
  if (data.type === 'result') {
    console.log(`Photo: ${data.filename} â†’ ${data.category} (${data.confidence}%)`);
  }
};
```

## ğŸ§ª Testing

### Run Tests

```bash
cd backend

# Run all tests with coverage
pytest tests/ -v --cov=app --cov-report=html

# Run specific test file
pytest tests/test_vision.py -v

# Run with GPU profiling
python -m torch.utils.bottleneck app/services/vision_service.py
```

### Load Testing

```bash
# Install locust
pip install locust

# Run load tests
locust -f tests/load_test.py --host http://localhost:8000
```

## ğŸ“š Resources & References

### Documentation
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [PyTorch Model Deployment](https://www.learnpytorch.io/09_pytorch_model_deployment/)
- [CUDA Installation Guide](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/)

### Tutorials & Guides
- [RunPod GPU Deployment](https://www.runpod.io/articles/guides/deploy-fastapi-applications-gpu-cloud)
- [Image Classification with FastAPI](https://nexusml.co/blog/image-classification-inference-fastapi/)
- [YOLOv8 GPU Optimization](https://www.labelvisor.com/optimizing-gpu-performance-for-yolov8/)
- [FastAPI ML Apps](https://www.kdnuggets.com/using-fastapi-for-building-ml-powered-web-apps)

### Video Resources
- [FastAPI + PyTorch Deployment](https://www.youtube.com/watch?v=x57vAQdBohQ)

### Example Implementations
- [Image Classification FastAPI Example](https://github.com/bernardcaldas/image-classification-fastapi)
- [PyTorch Multi-Instance GPU Inference](https://discuss.pytorch.org/t/how-to-deploy-multiple-instances-pytorch-model-api-for-inference-on-a-single-gpu/196044)

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines

- Follow PEP 8 style guidelines for Python code
- Add unit tests for new features (target: >80% coverage)
- Update documentation for API changes
- Test GPU functionality before submitting PRs
- Use meaningful commit messages

## ğŸ› Troubleshooting

### GPU Not Detected

```bash
# Check NVIDIA driver
nvidia-smi

# Verify CUDA installation
python -c "import torch; print(torch.cuda.is_available())"

# Check PyTorch CUDA version
python -c "import torch; print(torch.version.cuda)"
```

### Docker GPU Issues

```bash
# Verify NVIDIA Docker runtime
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi

# Check GPU visibility in container
docker exec photo-organizer nvidia-smi
```

### Performance Issues

- **Reduce batch size** if encountering OOM errors
- **Enable FP16** for 2x speedup on compatible GPUs
- **Monitor GPU memory** with `nvidia-smi -l 1`
- **Disable debug mode** in production (set `DEBUG=False`)

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [PyTorch](https://pytorch.org/) for the excellent deep learning framework
- [FastAPI](https://fastapi.tiangolo.com/) for the modern web framework
- [torchvision](https://pytorch.org/vision/) for pre-trained models
- [NVIDIA](https://www.nvidia.com/) for CUDA toolkit and GPU support

## ğŸ“ Support

- **Issues**: [GitHub Issues](https://github.com/zordhalo/photo-organizer/issues)
- **Documentation**: [Backend README](backend/README.md)

---

**Built with â¤ï¸ for construction professionals**

*Last Updated: December 2024*